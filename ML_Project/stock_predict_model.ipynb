{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb2RytJGjyQ1"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwWGgr7SiFlC"
      },
      "outputs": [],
      "source": [
        "# 1. Download stock data\n",
        "ticker = \"WBD\"\n",
        "df = yf.download(ticker, start=\"2015-01-01\", end=\"2025-01-01\")\n",
        "\n",
        "# 2. Add features\n",
        "df[\"Return\"] = df[\"Close\"].pct_change()\n",
        "df[\"MA_10\"] = df[\"Close\"].rolling(10).mean()\n",
        "df[\"MA_20\"] = df[\"Close\"].rolling(20).mean()\n",
        "df[\"Volatility\"] = df[\"Close\"].pct_change().rolling(10).std()\n",
        "df[\"RSI\"] = 100 - (100 / (1 + (df[\"Return\"].rolling(14).mean() / df[\"Return\"].rolling(14).std())))\n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "# Features: OHLCV + Return + MAs + Volatility\n",
        "feature_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Return\", \"MA_10\", \"MA_20\", \"Volatility\",\"RSI\"]\n",
        "data = df[feature_cols].values\n",
        "\n",
        "# Target: Next-day return\n",
        "target = df[\"Return\"].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvfnHXsQiOpd"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "target_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_target = target_scaler.fit_transform(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raKrCaiQhrhE"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = [], []\n",
        "window_size = 60\n",
        "for i in range(window_size, len(scaled_data)):\n",
        "    X_train.append(scaled_data[i-window_size:i])   # shape: (60, num_features)\n",
        "    y_train.append(scaled_target[i, 0])            # predict return\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "# Shape: (samples, timesteps=60, features=len(feature_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWjq-_Gshri5"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIi1NiWVhrml"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppGTC0yih2Y_"
      },
      "outputs": [],
      "source": [
        "# Save model + scalers\n",
        "model.save(f\"{ticker.lower()}_model.h5\")\n",
        "joblib.dump(scaler, f\"{ticker.lower()}_scaler.pkl\")\n",
        "joblib.dump(target_scaler, f\"{ticker.lower()}_target_scaler.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh2p3y0ikW9U"
      },
      "outputs": [],
      "source": [
        "def load_stock_model(ticker):\n",
        "    model = load_model(f\"{ticker.lower()}_model.h5\")\n",
        "    scaler = joblib.load(f\"{ticker.lower()}_scaler.pkl\")\n",
        "    target_scaler = joblib.load(f\"{ticker.lower()}_target_scaler.pkl\")\n",
        "    return model, scaler, target_scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWuLo9OXrltR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "\n",
        "def predict_with_stock_model(ticker, window_size=60):\n",
        "    # load model & scalers (assumes load_stock_model defined)\n",
        "    try:\n",
        "        model, scaler, target_scaler = load_stock_model(ticker)\n",
        "    except FileNotFoundError:\n",
        "        return f\"Model/scaler not found for {ticker}. Train it first.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error loading model/scaler: {e}\"\n",
        "\n",
        "    # fetch recent data\n",
        "    df = yf.download(ticker, period=\"6mo\", interval=\"1d\")\n",
        "    if df is None or df.shape[0] == 0:\n",
        "        return f\"No recent data for {ticker}.\"\n",
        "\n",
        "    # features same as training\n",
        "    df[\"Return\"] = df[\"Close\"].pct_change()\n",
        "    df[\"MA_10\"] = df[\"Close\"].rolling(window=10).mean()\n",
        "    df[\"MA_20\"] = df[\"Close\"].rolling(window=20).mean()\n",
        "    df[\"Volatility\"] = df[\"Close\"].pct_change().rolling(window=10).std()\n",
        "    df[\"RSI\"] = 100 - (100 / (1 + (df[\"Return\"].rolling(14).mean() / df[\"Return\"].rolling(14).std())))\n",
        "    df = df.dropna()\n",
        "\n",
        "    # check enough rows\n",
        "    if len(df) < window_size:\n",
        "        return f\"Not enough data to predict (need {window_size} rows, got {len(df)}).\"\n",
        "\n",
        "    # prepare features (ensure feature_cols exists in scope)\n",
        "    features = df[feature_cols].values  # feature_cols defined in your training pipeline\n",
        "    try:\n",
        "        scaled_features = scaler.transform(features)\n",
        "    except Exception as e:\n",
        "        return f\"Scaler transform error: {e}. Check feature order and scaler.\"\n",
        "\n",
        "    # model input\n",
        "    X_test = np.array([scaled_features[-window_size:]])  # shape (1, window_size, n_features)\n",
        "\n",
        "    # prediction (model.predict returns array)\n",
        "    predicted_return_scaled = model.predict(X_test)  # e.g. shape (1,1) or (1,)\n",
        "    predicted_return_scaled = np.asarray(predicted_return_scaled).reshape(-1, 1)  # ensure 2D for inverse_transform\n",
        "\n",
        "    # inverse transform safely\n",
        "    try:\n",
        "        predicted_return = target_scaler.inverse_transform(predicted_return_scaled)[0, 0]\n",
        "    except Exception:\n",
        "        # fallback: squeeze and convert to float\n",
        "        predicted_return = float(np.squeeze(predicted_return_scaled))\n",
        "\n",
        "    # ensure scalar float\n",
        "    predicted_return = float(np.squeeze(predicted_return))\n",
        "\n",
        "    # sanity checks\n",
        "    if np.isnan(predicted_return) or np.isinf(predicted_return):\n",
        "        return f\"Model returned non-finite predicted return: {predicted_return}\"\n",
        "\n",
        "    current_price = float(df[\"Close\"].values[-1])\n",
        "    predicted_price = current_price * (1 + predicted_return)\n",
        "\n",
        "    # decision thresholds\n",
        "    if predicted_return > 0.003:   # +0.3%\n",
        "      decision = \"BUY âœ…\"\n",
        "    elif predicted_return < -0.003: # -0.3%\n",
        "      decision = \"SELL âŒ\"\n",
        "    else:\n",
        "      decision = \"HOLD âš–ï¸\"\n",
        "\n",
        "    return f\"{ticker}: Current {current_price:.2f}, Predicted {predicted_price:.2f} (Return {predicted_return*100:.2f}%) â†’ {decision}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXq2q-dBrlwu"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"Chatbot: Goodbye ðŸ‘‹\")\n",
        "        break\n",
        "    try:\n",
        "        response = predict_with_stock_model(user_input.upper())\n",
        "        print(\"Chatbot:\", response)\n",
        "    except:\n",
        "        print(\"Chatbot: Sorry, I donâ€™t have a trained model for that ticker yet.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpTUYeQUsHj6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
